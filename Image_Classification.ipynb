{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2> Image Classification for Car Models </h2></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IyJ-vmxUwgIz"
   },
   "source": [
    "### Connecting to Google Drive\n",
    "- Installing PyDrive and mount Google Drive to Google Colab\n",
    "- Change the current directiory to current drive to access own drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwfqhjYnwqgu"
   },
   "outputs": [],
   "source": [
    "# Install PyDrive\n",
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7X6YCSgOwtfT"
   },
   "outputs": [],
   "source": [
    "# Mounting Google Drive\n",
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4benT9QwvaW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bHvr9kZwxQf"
   },
   "outputs": [],
   "source": [
    "# Change Directory to My Drive\n",
    "%cd drive\n",
    "%cd 'My Drive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsYXUfDXxXOD"
   },
   "source": [
    "### Data Pre-processing\n",
    "- Organise the images in a folder of their respective labels (classes)\n",
    "- Split into train and validation folders and copy the respective images over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jc9bCLP3w2Cp"
   },
   "outputs": [],
   "source": [
    "# Unzip the folder of training images\n",
    "!unzip train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVUfIA48xUFd"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Retrieve all the images in train folder and append them to a list\n",
    "train = []\n",
    "train_images = glob(os.path.join('data/train', \"*.jpg\"))\n",
    "for image in train_images:\n",
    "    x = plt.imread(image)\n",
    "    train.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XXysAle6TMJ"
   },
   "outputs": [],
   "source": [
    "# Retrieve the labels from the excel file and store it in a list\n",
    "test_labels = []\n",
    "labels_df = pd.ExcelFile('D:\\Competitions\\Grab Competition - Computer Vision\\\\test_labels.xlsx').parse('Sheet1')\n",
    "test_labels.append(labels_df['class'].values)\n",
    "test_labels = test_labels[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPezXjxo6n4d"
   },
   "outputs": [],
   "source": [
    "# Organise the training images in a folder of their respective labels\n",
    "final_train_labels = []\n",
    "counter = 0\n",
    "total_train = []\n",
    "total_train.append(train_df['fname'].values)\n",
    "total_train = total_train[0].tolist()\n",
    "for image in train_images:\n",
    "    counter = 0\n",
    "    for i in total_train:\n",
    "        i = 'data/train/' + i\n",
    "        if i == image:\n",
    "            final_train_labels.append(train_labels[counter])\n",
    "            break\n",
    "        counter += 1\n",
    "print(final_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rwtf5jj764Ig"
   },
   "outputs": [],
   "source": [
    "# Organise the test images in a folder of their respective labels\n",
    "destination = \"D:\\\\Competitions\\\\Grab Competition - Computer Vision\\\\test\"\n",
    "os.makedirs(destination)\n",
    "counter = 0\n",
    "classes_reg = []\n",
    "for image in test_images:\n",
    "    class_number = test_labels[counter]\n",
    "    dest = destination\n",
    "    dest += \"\\\\\" + str(class_number)\n",
    "    if class_number not in classes_reg:\n",
    "        os.makedirs(dest)\n",
    "        classes_reg.append(class_number)\n",
    "    shutil.copy(image,dest)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Osd7kaUC7AIs"
   },
   "outputs": [],
   "source": [
    "# Split the images into training and validation set of 80:20 ratio\n",
    "df = pd.DataFrame({'x' : train_images, 'y': train_labels})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, train_labels, test_size=0.2)\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))\n",
    "X_train = list(X_train.loc[:, 'x'])\n",
    "X_test = list(X_test.loc[:, 'x'])\n",
    "\n",
    "# Move the images into the respective directory\n",
    "train = \"D:\\Competitions\\Grab Competition - Computer Vision\\data1\\\\train\"\n",
    "val = \"D:\\Competitions\\Grab Competition - Computer Vision\\data1\\\\val\"\n",
    "os.makedirs(train)\n",
    "os.makedirs(val)\n",
    "for image in X_train:\n",
    "    shutil.copy(image, train)\n",
    "    \n",
    "for test in X_test:\n",
    "    shutil.copy(test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5JwM20m7NSW"
   },
   "outputs": [],
   "source": [
    "# Convert into numpy array for better performance and suitability for input for model\n",
    "val = np.asarray(val)\n",
    "np.save(\"test\", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpfz-wGMzx9r"
   },
   "source": [
    "### Data Augementation\n",
    "- To multiply training images to reduce overfitting with the use of augmentation\n",
    "- Instance Segmentation with pre-trained Mask RCNN model\n",
    "- Crop instances and paste it over self-selected background images\n",
    "- Filter the images and delete those unneeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juD3Im6qzy9A"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "# Downlaod Instance Segmentation Model to idenitify the mask\n",
    "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
    "\n",
    "# Change the directory to the Mask RCNN model\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))\n",
    "os.chdir('Mask_RCNN')\n",
    "ROOT_DIR = os.getcwd()\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"mrcnn/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import mrcnn\n",
    "import mrcnn.model as modellib\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "from mrcnn.visualize import display_images\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco\n",
    "# Instantiate a coco object\n",
    "config = coco.CocoConfig()\n",
    "COCO_DIR = '/content/drive/My Drive/data/train'\n",
    "\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtEkOBYV0bvo"
   },
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir='content/Mask_RCNN/mask_rcnn_coco.h5',\n",
    "                              config=config)\n",
    "\n",
    "# Set weights file path\n",
    "if config.NAME == \"coco\":\n",
    "    weights_path = COCO_MODEL_PATH\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Bg33ElA0oYp"
   },
   "outputs": [],
   "source": [
    "# Read the chosen background images and load them into a list\n",
    "background_images = []\n",
    "background_folder = glob(os.path.join('/content/drive/My Drive/background', '*.jpg'))\n",
    "  \n",
    "for p in background_folder:\n",
    "  background_images.append(plt.imread(str(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "L86hTwfd1bm1",
    "outputId": "bd990641-ee09-48c2-8ea2-97d08d55a928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "Processing 1 images\n",
      "image                    shape: (225, 300, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (299, 601, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (225, 300, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (194, 259, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (166, 300, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (360, 480, 3)         min:    0.00000  max:  228.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  123.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing 1 images\n",
      "image                    shape: (312, 416, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    }
   ],
   "source": [
    "# For every class and for every image, randomly select a background image\n",
    "# Crop out the mask of the image using the Mask RCNN model and paste the car instance segmented onto the background\n",
    "for j in range(0, 197):\n",
    "  images = []\n",
    "  os.chdir('/content/drive/My Drive/data/train/' + str(j))\n",
    "  folder = glob(os.path.join('/content/drive/My Drive/data/train/' + str(j), '*.jpg'))\n",
    "\n",
    "  for i in folder:\n",
    "    images.append(plt.imread(str(i)))\n",
    "\n",
    "  counter = 0\n",
    "  for k in images:\n",
    "    try:\n",
    "      results = model.detect([k], verbose=1)\n",
    "      mask = results[0]['masks']\n",
    "\n",
    "      temp_image = np.copy(k)\n",
    "      for m in range(k.shape[0]):\n",
    "        for n in range(k.shape[1]):\n",
    "          if mask[m][n][0] != False:\n",
    "            continue\n",
    "          else:\n",
    "            for l in range(3):\n",
    "              temp_image[m][n][l] = 0\n",
    "\n",
    "      index = random.randint(0, 19)\n",
    "      background = background_images[index]\n",
    "\n",
    "      edited_back = cv2.resize(background, (k.shape[1], k.shape[0]))\n",
    "      new_image = np.copy(edited_back)\n",
    "\n",
    "      for q in range(k.shape[0]):\n",
    "        for w in range(k.shape[1]):\n",
    "          for e in range(3):\n",
    "            if temp_image[q][w][e] != 0:\n",
    "              new_image[q][w][e] = temp_image[q][w][e]\n",
    "\n",
    "      counter = counter + 1\n",
    "      im = Image.fromarray(new_image)\n",
    "      im.save('new' + str(j) + \"_\" + str(counter) + '.png')\n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bk0OuTi1jYj"
   },
   "outputs": [],
   "source": [
    "# View the augmented images of each class to filter the required ones out\n",
    "os.chdir('/content/drive/My Drive/data/train/168')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 15)\n",
    "images_paths = os.listdir('/content/drive/My Drive/data/train/168')\n",
    "\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "pic_index = 36\n",
    "\n",
    "pic_index += 16\n",
    "pics = [os.path.join(fname) for fname in images_paths[pic_index-16:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(pics):\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4liZd24uxbLt"
   },
   "source": [
    "### Training Neural Networks\n",
    "- Prepare the image generator and the selected pre-trained models for transfer learning\n",
    "- Train the model through selected epochs\n",
    "- Plot the learning curve and the validation loss to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5dxhgunxojO"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from efficientnet import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create the directory for respective folders\n",
    "train_folder = os.path.join('/content/drive/My Drive/data/train')\n",
    "val_folder = os.path.join('/content/drive/My Drive/data/val')\n",
    "test_folder = os.path.join('/content/drive/My Drive/test')\n",
    "\n",
    "# Batch size\n",
    "bs_train = 6515\n",
    "bs_val = 1000\n",
    "bs_test = 6000\n",
    "\n",
    "# All images will be resized to this value\n",
    "image_size = (300, 300)\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   brightness_range= [0.5,1.5],\n",
    "                                   horizontal_flip=True,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.1,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images using train_datagen generator\n",
    "print(\"Preparing generator for train dataset\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder, \n",
    "    target_size=image_size,\n",
    "    batch_size=bs_train,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Flow validation images using val_datagen generator\n",
    "print(\"Preparing generator for validation dataset\")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory= val_folder, \n",
    "    target_size=image_size,\n",
    "    batch_size=bs_val,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Flow validation images using test_datagen generator\n",
    "print(\"Preparing generator for test dataset\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory= test_folder, \n",
    "    target_size=image_size, \n",
    "    batch_size=bs_test,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVj7h-lww58c"
   },
   "outputs": [],
   "source": [
    "# Install efficientnet\n",
    "!pip install -U git+https://github.com/qubvel/efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JrB0O8iOxz8C"
   },
   "outputs": [],
   "source": [
    "# Build Model using pre-trained weights\n",
    "base_model = EfficientNetB5(weights = 'imagenet', include_top = False, input_shape = (300, 300, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(196, activation = 'softmax'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tensorflow.keras.optimizers.RMSprop(lr = 0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16mpGk98x2f4"
   },
   "outputs": [],
   "source": [
    "# Check the layers of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJOrFDjkyJrD"
   },
   "outputs": [],
   "source": [
    "# Training Models\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch=train_generator.samples // bs_train + 1,\n",
    "        epochs=1,\n",
    "        validation_data=val_generator, \n",
    "        validation_steps=val_generator.samples // bs_val + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NonBACvyObV"
   },
   "outputs": [],
   "source": [
    "# Saving model in h5 format\n",
    "model.save('efficient.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building of second model\n",
    "base_model = InceptionResnet(weights = 'imagenet', include_top = False, input_shape = (300, 300, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(196, activation = 'softmax'))\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tensorflow.keras.optimizers.RMSprop(lr = 0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch=train_generator.samples // bs_train + 1,\n",
    "        epochs=1,\n",
    "        validation_data=val_generator, \n",
    "        validation_steps=val_generator.samples // bs_val + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model in h5 format\n",
    "model2.save('inceptionresnetv2_modelv6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGsXHsiKxF-B"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from efficientnet import load_model\n",
    "\n",
    "model_path = 'inceptionresnetv2_modelv6.h5'\n",
    "model1 = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gkUrx2KydVn"
   },
   "outputs": [],
   "source": [
    "# Plot validation loss graph\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBBdq4OayYxh"
   },
   "outputs": [],
   "source": [
    "# Plot learning curves to check for overfitting\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "be644PTWyjhc"
   },
   "source": [
    "### Ensemble Learning\n",
    "- Using Grid Search to find the best parameters for ensemble learning\n",
    "- The weighted combinations from models will provide the predicted outputs of best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKsWwKDAyoFk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import tensordot\n",
    "from numpy.linalg import norm\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "\n",
    "# Make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, weights, testX):\n",
    "\t# make predictions\n",
    "  yhats = [model.predict(testX) for model in members]\n",
    "  yhats = array(yhats)\n",
    "\t# weighted sum across ensemble members\n",
    "  summed = tensordot(yhats, weights, axes=((0),(0)))\n",
    "\t# argmax across classes\n",
    "  result = argmax(summed, axis=1)\n",
    "  return result\n",
    " \n",
    "# Evaluate a specific number of members in an ensemble\n",
    "def evaluate_ensemble(members, weights, testX, testy):\n",
    "  # make prediction\n",
    "  yhat = ensemble_predictions(members, weights, testX)\n",
    "  # calculate accuracy\n",
    "  score = accuracy_score(testy, yhat)\n",
    "  print(score, weights)\n",
    "  return score\n",
    " \n",
    "# Normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "\t# calculate l1 vector norm\n",
    "\tresult = norm(weights, 1)\n",
    "\t# check for a vector of all zeros\n",
    "\tif result == 0.0:\n",
    "\t\treturn weights\n",
    "\t# return normalized vector (unit norm)\n",
    "\treturn weights / result\n",
    " \n",
    "# Grid Search Weights\n",
    "def grid_search(members, testX, testy):\n",
    "\t# define weights to consider\n",
    "\tw = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tbest_score, best_weights = 0.0, None\n",
    "\t# iterate all possible combinations (cartesian product)\n",
    "\tfor weights in product(w, repeat=len(members)):\n",
    "\t\t# skip if all weights are equal\n",
    "\t\tif len(set(weights)) == 1:\n",
    "\t\t\tcontinue\n",
    "\t\t# hack, normalize weight vector\n",
    "\t\tweights = normalize(weights)\n",
    "\t\t# evaluate weights\n",
    "\t\tscore = evaluate_ensemble(members, weights, testX, testy)\n",
    "\t\tif score > best_score:\n",
    "\t\t\tbest_score, best_weights = score, weights\n",
    "\t\t\tprint('>%s %.3f' % (best_weights, best_score))\n",
    "\treturn list(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBj2g4VMy3Gb"
   },
   "outputs": [],
   "source": [
    "# Generate a batch of images for testing\n",
    "members = [model1, model2]\n",
    "test, test_labels = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1E5ShXevywrK"
   },
   "outputs": [],
   "source": [
    "# For every model, evaluate each model to get the evaluation score\n",
    "for i in range(1):\n",
    "\t_, test_acc = members[i].evaluate(test, test_labels, verbose=0)\n",
    "\tprint('Model %d: %.3f' % (i+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUikUi3qy_6x"
   },
   "outputs": [],
   "source": [
    "# Convert the test labels to required format for grid search\n",
    "index = tf.argmax(test_labels, axis = 1)\n",
    "session = tf.Session()\n",
    "test_labels = session.run(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyzkKnGNzQYx"
   },
   "outputs": [],
   "source": [
    "# Find the ideal weights which provides the most accurate outputs\n",
    "weights = grid_search(members, test, test_labels)\n",
    "score = evaluate_ensemble(members, weights, test, test_labels)\n",
    "print('Grid Search Weights: %s, Score: %.3f' % (weights, score))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Image Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
